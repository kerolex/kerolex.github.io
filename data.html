<!DOCTYPE html>
<html lang = "en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139569814-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139569814-1');
	</script>

	<title>Alessio Xompero, PhD</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="image" property="og:image" content="images/AlessioXompero.JPG">

	<link rel="shortcut icon" href="images/profile_icon_ax.JPG" />
	<link rel="stylesheet" href="../css/bootstrap.min.css" >
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="css/mystyle.css">
	<link rel="stylesheet" href="css/all.css">
	<link rel="stylesheet" href="css/academicons.css">
	
	<script src="js/pubs.js"></script>

</head>

<body>
	<div id="menu">
    <!-- <p style="float:left; font-size: 14.0pt;"><b style="font-weight: bold;">Alessio Xompero, Ph.D.</b></p> -->
    <div class="logo">
      <a href="index.html" class="active"><b>Alessio Xompero, Ph.D.</b></a>     
    </div>    
    <nav>
			<ul>			
			  <li>
			  	<div class="subnav">
				    <a >Research</a>
				    <div class="subnav-content">
				    	<a href="publications.html">Publications</a><br>
					    <a href="data.html">Data</a><br>
					    <a href="software.html">Software</a><br>
					    <a href="projects.html">Projects</a><br>
					    <a href="talks.html">Talks</a>
				    </div>
				</div>
			</li>
			<li>
				<div class="subnav">
					<a>Services</a>
				    <div class="subnav-content">
				    	<a href="services/teaching.html">Teaching</a><br>
				    	<a href="services/reviewing.html">Reviewing</a><br>
				    	<a href="services/openscience.html">Open Science</a>
				    </div>
				</div>
			</li>
			<li>
				<div class="subnav">
					<a>News</a>
				    <div class="subnav-content">
				    	<a href="news.html">All news</a><br>
				    	<a href="blog.html">Blog</a>
				    </div>
				</div>
			</li>
			<li>
				<div class="subnav">
					<a>About</a>
				    <div class="subnav-content">
				    	<a href="bio.html">Biography</a>
				    	<a href="gallery.html">Gallery</a>
				    </div>
				</div>
			</li>
			</ul>
		</nav>
  </div>


	<div id="about">
		<h2>Data</h2>
		<p>
			A list of dataset that I contributed to the collection, annotation, and release. 
		</p>
		<div>
			<table class="tg" width="100%">
				<tr>
					<td class="tg-km2t" style="vertical-align: text-top;">
						<a href="http://corsmal.eecs.qmul.ac.uk/containers_manip.html" TARGET = "_blank">
							<div class="imglnews" style="border:0">
								<video width="100%" autoplay loop><source  src="http://corsmal.eecs.qmul.ac.uk/resources/output_4.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></div>			  
								</a>
							</td>
							<td class="tg-zv4m" style="vertical-align: top;">
								<em style="color:#6699ff">CORSMAL Containers Manipulation</em><br><br>
								A dataset with 1140 audio-visual-inertial recordings of people interacting with (15) containers, using 4 cameras (RGB, depth, and infrared) and a 8-element circular microphone array. Containers are either empty of filled at 2 different levels (50%, 90%) with 3 different types of content (water, pasta, rice). For example, people can pour a liquid in a glass/cup or shake a food box.
								<br><br>
								[<a title="Dataset" href="http://corsmal.eecs.qmul.ac.uk/containers_manip.html" TARGET = "_blank"><u>details</u></a>]
								[<a class="papercite_pdf" title="BibTex" onclick="AppearBib('bib_ccm')"><u>bibtex</u></a>]      
								<div id="bib_ccm"  style="display:none;" class="bib pre-white-space">
									@misc{Xompero2020CCM,
									title = {CORSMAL Containers Manipulation},
									author = {Xompero, Alessio and Sanchez-Matilla, Ricardo, and Mazzon, Riccardo and Cavallaro, Andrea},
									organization={Queen Mary University of Londodn},
									doi={https://doi.org/10.17636/101CORSMAL1},
									year = {2020}
								}
							</div>
						</td>
					</tr>
					<tr>
					<td class="tg-km2t" style="vertical-align: text-top;">
						<a href="http://corsmal.eecs.qmul.ac.uk/containers.html" TARGET = "_blank">
							<img src="images/corsmal_containers.png" alt="Containers"  width="100%" style="vertical-align: middle;"/></a>
							</td>
							<td class="tg-zv4m" style="vertical-align: top;">
								<em style="color:#6699ff">CORSMAL Containers</em><br><br>
								A vision dataset of 23 transparent and non-transparent containers, such as drinking cups, drinking glasses and bottles. Each container lies on a table in two different setups with different lighting and background conditions, and is observed by two cameras with a wide-baseline, acquiring RGB, depth, and narrow-baseline stereo infrared images.
								<br><br>
								[<a title="Dataset" href="http://corsmal.eecs.qmul.ac.uk/containers.html" TARGET = "_blank"><u>details</u></a>]
								[<a class="papercite_pdf" title="BibTex" onclick="AppearBib('bib_containers')"><u>bibtex</u></a>]      
								<div id="bib_containers"  style="display:none;" class="bib pre-white-space">
									@misc{Xompero2020CCM,
									title = {CORSMAL Containers},
									author = {Xompero, Alessio and Sanchez-Matilla, Ricardo, and Mazzon, Riccardo and Cavallaro, Andrea},
									organization={Queen Mary University of Londodn},
									doi={https://doi.org/10.17636/corsmal2},
									year = {2020}
								}
							</div>
						</td>
					</tr>
					<tr>
					<td class="tg-km2t" style="vertical-align: text-top;">
						<a href="https://speechtek.fbk.eu/cav3d-dataset/" TARGET = "_blank">
							<img src="images/CAV3D.png" alt="CAV3D"  width="100%" style="vertical-align: middle;"/></a>
							</td>
							<td class="tg-zv4m" style="vertical-align: top;">
								<em style="color:#6699ff">CAV3D (Co-located Audio-Visual streams with 3D tracks)</em><br><br>
								A dataset for 3D speaker tracking was collected with a sensing platform consisting of a monocular colour camera co-located with an 8-element circular microphone array. The audio sampling rate is 96 kHz. Video was recorded at 15 frames per second. The sensing platform was placed on a table in a room with dimensions 4.77 x 5.95 x 4.5 m and reverberation time of approximately 0.7s to record up to three simultaneous speakers. In addition to the sensing platform, 4 hardware-triggered CCD colour cameras installed at the top corners of the room recorded the scene. The dataset is synchronized, calibrated and annotated.
								<br><br>
								[<a title="Dataset" href="https://speechtek.fbk.eu/cav3d-dataset/" TARGET = "_blank"><u>details</u></a>]
								[<a class="papercite_pdf" title="BibTex" onclick="AppearBib('bib_cav3d')"><u>bibtex</u></a>]      
								<div id="bib_cav3d"  style="display:none;" class="bib pre-white-space">
									@article{Qian2019TMM,
									title = {Multi-speaker tracking from an audio-visual sensing device},
									author = {Qian, X. and Brutti, A., and Omologo, L. and Cavallaro, Andrea},
									journal={IEEE Transactions on Multimedia},
									volume={21},
									number={10},
									month=mar,
									year = {2019}
								}
							</div>
						</td>
					</tr>
					<!-- -->
					<tr>
					<td class="tg-km2t" style="vertical-align: text-top;">
						<a href="http://loki.disi.unitn.it/MediaEvalSEM2015/" TARGET = "_blank">
							<div align="centre" style="text-align:center;">
								<img src="images/MediaEvalSEM2014/Mediaeval.jpg" alt="MediaEvalSEM2015"  width="80%" style="vertical-align: middle;"/>
								<br><br>
								<img src="images/MediaEvalSEM2015/16404656271_56c78986de_o.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2015/3_17.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2015/10_37.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>
								<br><br>
								<img src="images/MediaEvalSEM2015/9_1.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2015/9_38.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2015/16421670662_93ffc640ba_o.jpg" alt="MediaEvalSEM2015"  width="32%" style="vertical-align: middle;"/>	
							</div>
						</a>
							</td>
							<td class="tg-zv4m" style="vertical-align: top;text-align: justify;">
								<em style="color:#6699ff">Tour de France 2014, NAMM 2015, Spring Party Salesiani 2015</em><br><br>
								These datasets were collected and been part of the <i>Synchronization of Multi-User Event Media (SEM) at MediaEval 2015: Task Description, Datasets, and Evaluation</i>. Tour de France 2014 consists of images taken during the event and collected from Flickr. The dataset, split into 33 galleries, covers the entire competition. NAMM 2015 consists of 420 images downloaded from Flickr and 32 videos downloaded from YouTube. The dataset, split into 19 galleries, is related to the famous event held in California. The Spring Party Salesiani 2015 is a dataset collected by the organizers, and recorded duringa students' party held in Trento, Italy. It is composed of videos and pictures captured by the attendees during the event.
								<br><br>
								[<a title="Dataset" href="http://loki.disi.unitn.it/MediaEvalSEM2015/" TARGET = "_blank"><u>details</u></a>]
								[<a title="PDF" href="https://www.iti.gr/~bmezaris/publications/mediaeval15sem_overview.pdf" TARGET = "_blank"><u>paper</u></a>]
						</td>
					</tr>
					<!-- -->
					<tr>
					<td class="tg-km2t" style="vertical-align: text-top;">
						<a href="http://loki.disi.unitn.it/MediaEvalSEM2014/" TARGET = "_blank">
							<div align="centre" style="text-align:center;">
								<img src="images/MediaEvalSEM2014/Mediaeval.jpg" alt="MediaEvalSEM2014"  width="80%" style="vertical-align: middle;"/>
								<br><br>
								<img src="images/MediaEvalSEM2014/beach.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2014/federer.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>
								<img src="images//MediaEvalSEM2014/circles.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>
								<br><br>
								<img src="images/MediaEvalSEM2014/ski.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2014/leaves.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>
								<img src="images/MediaEvalSEM2014/skating.jpg" alt="MediaEvalSEM2014"  width="32%" style="vertical-align: middle;"/>	
							</div>
						</a>
							</td>
							<td class="tg-zv4m" style="vertical-align: top;text-align: justify;">
								<em style="color:#6699ff">London Olympics and Vancouver Olympics Datasets</em><br><br>
								As part of the <i>Synchronization of Multi-User Event Media (SEM) at MediaEval 2014: Task Description, Datasets, and Evaluation</i>, these datasets are a collection of images referring to structured sport events, namely the Olympic Games held in London in 2012 nad the Vancouver Winter Olympic Games of 2010. London Olympics includes 2124 images, divided into 37 galleries. Vancouver Winter Olympic Games includes 1351 pictures representing most of the competitions, divided into 35 galleries with a variable number of pictures in each gallery. 
								The images were gathered from Flickr and made available under Creative Commons license.   
								<br><br>
								[<a title="Dataset" href="http://loki.disi.unitn.it/MediaEvalSEM2014/" TARGET = "_blank"><u>details</u></a>]
								[<a title="PDF" href="https://ceur-ws.org/Vol-1263/mediaeval2014_submission_32.pdf" TARGET = "_blank"><u>paper</u></a>]
						</td>
					</tr>
				</table>
				<br>
			</div>
		</div>
<br><br><br>
<footer class="site-footer">
		<div class="footer-col social-col" style="text-align:center;">  
				<a href="https://twitter.com/aXompi"><i class="fab fa-fw fa-twitter" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US"><i class="fab fa-fw fa-linkedin" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://github.com/kerolex/"><i class="fab fa-fw fa-github" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://orcid.org/0000-0002-8227-8529"><i class="ai ai-orcid ai-fw" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao"><i class="ai ai-fw ai-google-scholar" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
			</div>
		<p>
			Copyright © 2015-2025 - Alessio Xompero
		</p>
</footer>
</body>
</html>
<!DOCTYPE html>
<html lang = "en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139569814-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139569814-1');
	</script>

	<title>Alessio Xompero</title>

	<link href = "css/bootstrap.min.css" rel = "stylesheet">
	<link rel="stylesheet" href="mystyle.css">

	<style>
	h2{
			text-align: left;
			/*color: #017572;*/
			color: #6699ff;
		}
		#about, #services {
			width: 50%;
			text-align: left;
			margin-top: 0px;
			margin:0 auto;
			white-space: break-all;
		}
	</style>
</head>

<body>
<div id="about">
	<p style="float:left">Alessio Xompero</p>
	<nav style="text-align:center">
		<ul>
			<!-- <li>Alessio Xompero</li> -->
			<li><a href="index.html" class="active">Home</a></li>
			<li><a href="publications.html">Publications</a></li>
			<li><a href="data.html">Data</a></li>
			<li><a href="bio.html">Biography</a></li>
		</ul>
	</nav>
</div>


	<div id="about">

		<h2 style="text-align: left;">CORSMAL Containers Manipulation</h2>
		<p>
			A dataset with 1140 audio-visual-inertial recordings of people interacting with (15) containers, using 4 cameras (RGB, depth, and infrared) and a 8-element circular microphone array. Containers are either empty of filled at 2 different levels (50%, 90%) with 3 different types of content (water, pasta, rice). For example, people can pour a liquid in a glass/cup or shake a food box.
		</p>
		<a href="http://corsmal.eecs.qmul.ac.uk/containers_manip.html">Link</a>

		<h2 style="text-align: left;">CORSMAL Containers</h2>
		<p>
			A vision dataset of 23 transparent and non-transparent containers, such as drinking cups, drinking glasses and bottles. Each container lies on a table in two different setups with different lighting and background conditions, and is observed by two cameras with a wide-baseline, acquiring RGB, depth, and narrow-baseline stereo infrared images. 
		</p>
		<a href="http://corsmal.eecs.qmul.ac.uk/containers.html">Link</a>

		<h2 style="text-align: left;">CAV3D (Co-located Audio-Visual streams with 3D tracks)</h2>
		<p>
			A dataset for 3D speaker tracking was collected with a sensing platform consisting of a monocular colour camera co-located with an 8-element circular microphone array. The audio sampling rate is 96 kHz. Video was recorded at 15 frames per second. The sensing platform was placed on a table in a room with dimensions 4.77 x 5.95 x 4.5 m and reverberation time of approximately 0.7s to record up to three simultaneous speakers. In addition to the sensing platform, 4 hardware-triggered CCD colour cameras installed at the top corners of the room recorded the scene. The dataset is synchronized, calibrated and annotated.
		</p>
		<a href="https://ict.fbk.eu/units/speechtek/cav3d/">Link</a>
		
	</div>
</body>
</html>



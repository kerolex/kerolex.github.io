<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd%22%3E
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="EN" lang="EN" dir="ltr">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139569814-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139569814-1');
	</script>
	<title>Alessio Xompero, PhD</title>
	<!-- <meta http-equiv="refresh" content="0; url=https://whataboutcomputervision.wordpress.com/" /> -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="image" property="og:image" content="../images/AlessioXompero.JPG">

	<link rel="shortcut icon" href="../images/profile_icon_ax.JPG" />
	<link rel="stylesheet" href="../css/bootstrap.min.css" >
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="../css/mystyle.css">
	<link rel="stylesheet" href="../css/all.css">
	<link rel="stylesheet" href="../css/academicons.css">

	<script src="../js/menu.js" defer></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #1a1a2e;
            --secondary: #16213e;
            --accent: #e94560;
            --accent-light: #ff6b7a;
            --text: #f0f0f0;
            --text-muted: #b0b0b0;
            --border: #2a2a3e;
            --bg: #0f0f1e;
        }

        body {
            font-family: 'Segoe UI', 'Trebuchet MS', sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.7;
            overflow-x: hidden;
        }

        /* Header & Hero */
        .hero {
            background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 100%);
            border-bottom: 2px solid var(--accent);
            padding: 80px 20px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .hero::before {
            content: '';
            position: absolute;
            top: -50%;
            right: -20%;
            width: 500px;
            height: 500px;
            background: radial-gradient(circle, var(--accent) 0%, transparent 70%);
            opacity: 0.1;
            pointer-events: none;
        }

        .hero-content {
            position: relative;
            z-index: 1;
            max-width: 900px;
            margin: 0 auto;
        }

        .hero h1 {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 20px;
            background: linear-gradient(90deg, var(--text) 0%, var(--accent-light) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: slideDown 0.8s ease-out;
        }

        .hero .subtitle {
            font-size: 1.3rem;
            color: var(--text-muted);
            margin-bottom: 30px;
            animation: fadeIn 1s ease-out 0.3s backwards;
        }

        .hero .meta {
            display: flex;
            justify-content: center;
            gap: 30px;
            flex-wrap: wrap;
            font-size: 0.95rem;
            color: var(--text-muted);
            animation: fadeIn 1s ease-out 0.6s backwards;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        /* Main Content */
        .container {
            max-width: 850px;
            margin: 0 auto;
            padding: 60px 20px;
        }

        .post-content {
            background: var(--primary);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 50px;
            margin-bottom: 40px;
        }

        h2 {
            font-size: 2rem;
            margin-top: 45px;
            margin-bottom: 20px;
            color: var(--accent-light);
            border-left: 4px solid var(--accent);
            padding-left: 15px;
            position: relative;
        }

        h2:first-child {
            margin-top: 0;
        }

        h3 {
            font-size: 1.4rem;
            margin-top: 30px;
            margin-bottom: 15px;
            color: var(--text);
        }

        p {
            margin-bottom: 18px;
            color: var(--text);
            line-height: 1.8;
        }

        p strong {
            color: var(--accent-light);
        }

        /* Lists */
        ul, ol {
            margin-left: 20px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            color: var(--text);
        }

        li strong {
            color: var(--accent-light);
        }

        /* Highlight Box */
        .highlight-box {
            background: linear-gradient(135deg, rgba(233, 69, 96, 0.1) 0%, rgba(233, 69, 96, 0.05) 100%);
            border-left: 4px solid var(--accent);
            border-radius: 8px;
            padding: 25px;
            margin: 30px 0;
            border-top: 1px solid var(--accent);
        }

        .highlight-box h4 {
            color: var(--accent-light);
            margin-bottom: 12px;
            font-size: 1.1rem;
        }

        .highlight-box p {
            margin-bottom: 8px;
            font-size: 0.95rem;
        }

        /* Track Description */
        .track-card {
            background: linear-gradient(135deg, var(--secondary) 0%, rgba(233, 69, 96, 0.05) 100%);
            border: 2px solid var(--accent);
            border-radius: 12px;
            padding: 30px;
            margin: 30px 0;
            position: relative;
            overflow: hidden;
        }

        .track-card::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 200px;
            height: 200px;
            background: radial-gradient(circle, var(--accent) 0%, transparent 70%);
            opacity: 0.08;
            pointer-events: none;
        }

        .track-card h3 {
            color: var(--accent-light);
            margin-top: 0;
            position: relative;
            z-index: 1;
        }

        .track-card p {
            position: relative;
            z-index: 1;
        }

        /* Opportunities Section */
        .opportunities {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 30px 0;
        }

        .opportunity-item {
            background: rgba(233, 69, 96, 0.08);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px;
            transition: all 0.3s ease;
        }

        .opportunity-item:hover {
            border-color: var(--accent);
            background: rgba(233, 69, 96, 0.12);
            transform: translateY(-2px);
        }

        .opportunity-item strong {
            color: var(--accent-light);
            display: block;
            margin-bottom: 8px;
        }

        .opportunity-item p {
            font-size: 0.95rem;
            margin: 0;
        }

        @media (max-width: 768px) {
            .opportunities {
                grid-template-columns: 1fr;
            }

            .hero h1 {
                font-size: 2.5rem;
            }

            .post-content {
                padding: 30px 20px;
            }

            h2 {
                font-size: 1.6rem;
            }

            .meta {
                gap: 15px;
                font-size: 0.85rem;
            }
        }

        /* Call-to-Action */
        .cta-section {
            background: linear-gradient(135deg, var(--accent) 0%, var(--accent-light) 100%);
            border-radius: 12px;
            padding: 40px;
            text-align: center;
            color: white;
            margin: 40px 0;
        }

        .cta-section h3 {
            color: white;
            margin-top: 0;
            font-size: 1.8rem;
        }

        .cta-section p {
            color: rgba(255, 255, 255, 0.95);
            margin-bottom: 25px;
            font-size: 1.05rem;
        }

        .cta-buttons {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            display: inline-block;
            padding: 12px 28px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 600;
            font-size: 0.95rem;
            transition: all 0.3s ease;
            border: 2px solid transparent;
            cursor: pointer;
        }

        .btn-primary {
            background: white;
            color: var(--accent);
            border-color: white;
        }

        .btn-primary:hover {
            background: transparent;
            color: white;
        }

        .btn-secondary {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border-color: white;
        }

        .btn-secondary:hover {
            background: white;
            color: var(--accent);
        }

        /* Deadline Box */
        .deadline-box {
            background: var(--secondary);
            border: 2px dashed var(--accent);
            border-radius: 8px;
            padding: 20px;
            margin: 30px 0;
            text-align: center;
        }

        .deadline-box p {
            margin: 0;
            font-size: 1.1rem;
            font-weight: 600;
        }

        .deadline-date {
            color: var(--accent-light);
            font-size: 1.4rem;
            margin-top: 8px;
        }

        /* Footer */
        footer {
            background: var(--secondary);
            border-top: 1px solid var(--border);
            padding: 40px 20px;
            text-align: center;
            color: var(--text-muted);
        }

        footer a {
            color: var(--accent-light);
            text-decoration: none;
            transition: color 0.3s ease;
        }

        footer a:hover {
            color: var(--accent);
        }

        .footer-links {
            display: flex;
            justify-content: center;
            gap: 25px;
            flex-wrap: wrap;
            margin-bottom: 20px;
            font-size: 0.9rem;
        }

        /* Animations */
        @keyframes slideDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }
            to {
                opacity: 1;
            }
        }

        /* Emoji styling */
        .emoji {
            display: inline-block;
            font-size: 1.2em;
        }

        code {
            background: var(--secondary);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: var(--accent-light);
            font-size: 0.9em;
        }

        a {
            color: var(--accent-light);
            text-decoration: none;
            transition: color 0.3s ease;
            border-bottom: 1px solid transparent;
        }

        a:hover {
            color: var(--accent);
            border-bottom-color: var(--accent);
        }
    </style>
</head>
<body>
		<div id="menu">
		<div class="logo">
			<a href="../index.html" class="active"><b>Alessio Xompero, Ph.D.</b></a>			
		</div>

		<!-- From https://www.menucool.com/ddmenu/one-menu-for-all-pages -->
		<nav>
			<div class="menu-toggle"><span></span></div>
			<ul>			
				<li class="subnav">
					<a>Research</a>
					<div class="subnav-content">
						<a href="../research/publications.html">Publications</a>
						<!-- <br> -->
						<a href="../research/data.html">Data</a>
						<!-- <br> -->
						<a href="../research/software.html">Software</a>
						<!-- <br> -->
						<a href="../research/projects.html">Projects</a>
						<!-- <br> -->
						<a href="../research/talks.html">Talks</a>
					</div>
				</li>
				<li class="subnav">
					<a>Services</a>
					<div class="subnav-content">
						<!-- <a href="services/teaching.html">Teaching</a><br> -->
						<a href="../services/reviewing.html">Reviewing</a>
						<!-- <br> -->
						<a href="../services/openscience.html">Community</a>
					</div>
				</li>
				<li class="subnav">
					<a>Teaching</a>
					<div class="subnav-content">
						<a href="../teaching/teaching.html">Teaching</a>
					</div>
				</li>
				<li class="subnav">
					<a>News</a>
					<div class="subnav-content">
						<a href="../news.html">All news</a>
						<!-- <br> -->
						<a href="../blog.html">Blog</a>
					</div>
				</li>
				<li class="subnav">
					<a>About</a>
					<div class="subnav-content">
						<a href="../bio.html">Biography</a>
						<!-- <br> -->
						<a href="../gallery.html">Gallery</a>
					</div>
				</li>
			</ul>
		</nav>
	</div>
	<!--  -->
	<div id="section">
		<div class="scrolling-content">
			<h2>Blog</h2>
			See also my former WordPress site <a href="https://whataboutcomputervision.wordpress.com/"><u>whataboutcomputervision</u></a> for older blog posts.
			<br><br>
			<div id="rgmc11-icra26">
                <!-- Hero Section -->
    <div class="hero">
        <div class="hero-content">
            <h1>Advancing Robotic Grasping in the Real World</h1>
            <p class="subtitle">Join the 11th Robotic Grasping and Manipulation Competition</p>
            <div class="meta">
                <div class="meta-item">üìç Vienna, Austria</div>
                <div class="meta-item">üóìÔ∏è ICRA 2026</div>
                <div class="meta-item">ü§ñ 4 Competition Tracks</div>
            </div>
        </div>
    </div>

    <!-- Main Content -->
    <div class="container">
        <div class="post-content">
            <!-- Introduction -->
            <h2>The Challenge Ahead</h2>
            <p>Robotics has made tremendous strides in recent years, yet one of the most fundamental tasks‚Äîgrasping and manipulating objects‚Äîremains deeply challenging in real-world settings. The <strong>11th Robotic Grasping and Manipulation Competition (RGMC)</strong> brings together researchers, engineers, and innovators to tackle this problem head-on.</p>

            <p>Held during the <strong>2026 IEEE/RAS International Conference on Robotics and Automation (ICRA)</strong> in Vienna, RGMC provides a unique platform to benchmark your work against state-of-the-art solutions and advance robotic manipulation in practical, unconstrained environments.</p>

            <div class="highlight-box">
                <h4>üéØ Why Participate?</h4>
                <p>RGMC isn't just a competition‚Äîit's a community-driven initiative to solve real problems in robotic manipulation. Whether you're an academic lab, industry team, or student group, you'll gain access to cutting-edge hardware, publish peer-reviewed research, and compete for recognition and cash prizes.</p>
            </div>

            <!-- Overview -->
            <h2>What is RGMC?</h2>
            <p>The Robotic Grasping and Manipulation Competition is an annual event that challenges teams to develop robust solutions for grasping and manipulating objects in real-world conditions. Unlike simulated environments, RGMC emphasizes practical constraints: variable lighting, occlusions, object variability, and the unpredictability of physical interaction.</p>

            <p>With four specialized tracks, RGMC covers different aspects of robotic manipulation:</p>

            <ul>
                <li><strong>Human-to-Robot Handovers</strong> ‚Äì Robots that can safely receive objects handed by humans</li>
                <li><strong>Object Singulation</strong> ‚Äì Separating and isolating individual items from heaps</li>
                <li><strong>Pick-and-Place Tasks</strong> ‚Äì Accurate object grasping and relocation</li>
                <li><strong>Pushing and Non-prehensile Manipulation</strong> ‚Äì Moving objects without grasping</li>
            </ul>

            <!-- Handover Track Focus -->
            <h2>The Human-to-Robot Handover Track</h2>
            <p>This year, we're spotlighting the <strong>Human-to-Robot Handover track</strong>, which addresses one of the most critical challenges in collaborative robotics: enabling safe, reliable transfer of objects from human hands to robotic grippers.</p>

            <div class="track-card">
                <h3>ü´±ü•§ü§ñ Real-Time Physical Property Estimation</h3>
                <p>The core challenge: <strong>Can your robot estimate what it's receiving‚Äîin real-time‚Äîand respond safely?</strong></p>
                <p>Teams must design solutions that enable robots to infer the physical properties (mass, stiffness, fill level) of objects during dynamic handovers, using only affordable vision-based perception. This is harder than it sounds. Consider the real-world complexities:</p>
                <ul style="margin-top: 15px;">
                    <li><strong>Unknown objects:</strong> Food containers and drinking glasses of varying shapes and sizes</li>
                    <li><strong>Unknown content:</strong> Containers may be empty or filled with unknown substances at unknown levels</li>
                    <li><strong>Unknown physics:</strong> The robot must estimate mass and stiffness on-the-fly, with no prior knowledge</li>
                    <li><strong>Perceptual challenges:</strong> Illumination variations, reflections, transparencies, and occlusions from both the human and robot</li>
                    <li><strong>Hardware constraints:</strong> No motion capture systems, markers, or specialized sensors‚Äîonly affordable cameras</li>
                </ul>
            </div>

            <h3>Why This Matters</h3>
            <p>Human-robot handover is fundamental to collaborative robotics. From manufacturing to assistive robotics to household automation, robots that can safely receive objects from humans open entirely new possibilities. However, the task demands simultaneous excellence in:</p>

            <ul>
                <li><strong>Perception:</strong> Inferring object properties from visual data</li>
                <li><strong>Control:</strong> Adapting grasp strategy based on estimated properties</li>
                <li><strong>Safety:</strong> Ensuring stable receipt without dropping or damaging</li>
                <li><strong>Generalization:</strong> Handling previously unseen objects and variations</li>
            </ul>

            <p>By solving handover, we're pushing robotics closer to real-world deployment in diverse environments.</p>

            <!-- What Participants Get -->
            <h2>What Participants Gain</h2>
            <p>RGMC offers far more than competition glory. Here's what participating teams receive:</p>

            <div class="opportunities">
                <div class="opportunity-item">
                    <strong>ü§ñ Real Hardware Access</strong>
                    <p>Test your algorithms on UR5 and Franka Emika Panda robots at the competition site (based on availability)</p>
                </div>
                <div class="opportunity-item">
                    <strong>üìä Benchmark & Research</strong>
                    <p>Benchmark against state-of-the-art solutions and contribute to advancing the field in real conditions</p>
                </div>
                <div class="opportunity-item">
                    <strong>üìù Publication Opportunity</strong>
                    <p>Contribute peer-reviewed research articles to the Topical Collection in <em>Autonomous Robots</em> on "Advancing Robotic Grasping and Manipulation for the Real-World"</p>
                </div>
                <div class="opportunity-item">
                    <strong>üì∫ Global Visibility</strong>
                    <p>Showcase your demo video on the RGMC YouTube channel, reaching the research community worldwide</p>
                </div>
                <div class="opportunity-item">
                    <strong>üíª Free Tools</strong>
                    <p>Secure a free MATLAB license to support your solution development</p>
                </div>
                <div class="opportunity-item">
                    <strong>üèÜ Recognition & Prizes</strong>
                    <p>Win cash rewards for top-performing teams and earn recognition at ICRA 2026</p>
                </div>
            </div>

            <!-- Important Dates -->
            <h2>Key Dates & Application Process</h2>

            <div class="deadline-box">
                <p>‚è∞ Extended Application Deadline</p>
                <div class="deadline-date">23 February 2026</div>
                <p style="font-size: 0.9rem; color: var(--text-muted); margin-top: 10px;">Maximum of 6 teams will qualify for on-site participation</p>
            </div>

            <p><strong>How to Apply:</strong> Fill out the registration form at: <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0ZXvTqP-bP9he-R2aoC4QZjUnlG_qPDJcfQWrcxvJGZ-sSw/viewform?usp=header" target="_blank">RGMC Registration Form</a></p>

            <p><strong>Note:</strong> Applications after the deadline may be considered based on available spots and solution readiness. With 33 teams already applied across all four tracks, early submission is recommended.</p>

            <!-- Learn More -->
            <h2>Get Started</h2>
            <p>Ready to join? Here are your next steps:</p>

            <ol>
                <li><strong>Visit the official RGMC website:</strong> <a href="https://sites.google.com/view/rgmcomp" target="_blank">https://sites.google.com/view/rgmcomp</a></li>
                <li><strong>Explore detailed track information:</strong> <a href="https://corsmal.github.io/events/rgmc/icra2026/" target="_blank">https://corsmal.github.io/events/rgmc/icra2026/</a></li>
                <li><strong>Submit your application</strong> by 23 February 2026</li>
                <li><strong>Prepare your solution</strong> and test it on the competition hardware</li>
                <li><strong>Showcase your work</strong> at ICRA 2026 in Vienna</li>
            </ol>

            <!-- Why RGMC Matters -->
            <h2>The Future of Robotic Manipulation</h2>
            <p>RGMC represents a shift in how we approach robotic research. Rather than isolated labs benchmarking against synthetic datasets, the competition brings diverse teams together to solve shared problems in realistic conditions. This collaborative approach accelerates innovation and ensures research translates to practical deployment.</p>

            <p>The handover track exemplifies this philosophy. By focusing on a specific, well-defined challenge‚Äîsafe transfer of unknown objects‚Äîwe create a shared benchmark that drives rapid progress across vision, control, and sensing.</p>

            <p>Whether you're developing perception algorithms, designing adaptive control strategies, or building novel sensor systems, RGMC provides the platform and resources to validate your work at scale.</p>

            <!-- Call to Action -->
            <div class="cta-section">
                <h3>Ready to Advance Robotic Manipulation?</h3>
                <p>Join 33+ teams competing at the cutting edge of real-world robotics. The Human-to-Robot Handover track awaits your innovation.</p>
                <div class="cta-buttons">
                    <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0ZXvTqP-bP9he-R2aoC4QZjUnlG_qPDJcfQWrcxvJGZ-sSw/viewform?usp=header" class="btn btn-primary" target="_blank">Apply Now</a>
                    <a href="https://corsmal.github.io/events/rgmc/icra2026/" class="btn btn-secondary" target="_blank">Learn More</a>
                </div>
            </div>

            <h2>About the Competition</h2>
            <p>The Robotic Grasping and Manipulation Competition is organized by leading researchers in robotics and supported by industry partners committed to advancing autonomous manipulation. RGMC takes place annually at top-tier robotics conferences, creating a global forum for collaborative research.</p>

            <p><strong>Questions?</strong> Visit the official websites or contact the organizers directly through the competition platform.</p>

        </div>
    </div>
				
			</div>
		</div>
	</div>

    <main>
        <article>
            <header class="article-header">
                <span class="post-category-badge">Competition</span>
                <h1>Advancing Robotic Grasping in the Real World</h1>
                <div class="article-meta">
                    <span>üìÖ February 2026</span>
                    <span>‚úçÔ∏è RGMC Organizers</span>
                    <span>‚è±Ô∏è 10 min read</span>
                </div>
            </header>

            <div class="article-content">
                <!-- Introduction -->
                <h2>The Challenge Ahead</h2>
                <p>Robotics has made tremendous strides in recent years, yet one of the most fundamental tasks‚Äîgrasping and manipulating objects‚Äîremains deeply challenging in real-world settings. The <strong>11th Robotic Grasping and Manipulation Competition (RGMC)</strong> brings together researchers, engineers, and innovators to tackle this problem head-on.</p>

                <p>Held during the <strong>2026 IEEE/RAS International Conference on Robotics and Automation (ICRA)</strong> in Vienna, RGMC provides a unique platform to benchmark your work against state-of-the-art solutions and advance robotic manipulation in practical, unconstrained environments.</p>

                <div class="highlight-box">
                    <strong>üéØ Why Participate?</strong><br>
                    <p>RGMC isn't just a competition‚Äîit's a community-driven initiative to solve real problems in robotic manipulation. Whether you're an academic lab, industry team, or student group, you'll gain access to cutting-edge hardware, publish peer-reviewed research, and compete for recognition and cash prizes.</p>
                </div>

                <!-- Overview -->
                <h2>What is RGMC?</h2>
                <p>The Robotic Grasping and Manipulation Competition is an annual event that challenges teams to develop robust solutions for grasping and manipulating objects in real-world conditions. Now in its <strong>11th edition</strong>, RGMC has been running since 2016 at either ICRA or IROS, engaging the community with diverse tasks for manufacturing, service robotics, and logistics. Previous editions have featured challenges including assembling and disassembling boards, hand-in-hand grasping, picking and placing various objects, pouring liquids, bin picking, table arrangement, and cloth folding. Unlike simulated environments, RGMC emphasizes practical constraints: variable lighting, occlusions, object variability, and the unpredictability of physical interaction.</p>

                <p>The 2026 edition features four specialized tracks covering different aspects of robotic manipulation:</p>

                <ul>
                    <li><strong>Human-to-Robot Handover</strong> (3rd edition) ‚Äì Robots that safely estimate object properties and receive items handed by humans, then deliver them to target locations</li>
                    <li><strong>Picking from Clutter</strong> ‚Äì Grasping and removing objects from cluttered environments</li>
                    <li><strong>Mobile Manipulation</strong> ‚Äì Combining mobility and manipulation tasks (in collaboration with PAL Robotics)</li>
                    <li><strong>Cloud Robotics</strong> ‚Äì Remote manipulation using CloudGripper platform at KTH Royal Institute of Technology, including planar pushing and deformable object control</li>
                </ul>

                <!-- Handover Track Focus -->
                <h2>The Human-to-Robot Handover Track</h2>
                <p>This year, we're spotlighting the <strong>Human-to-Robot Handover track</strong>‚Äînow in its <strong>3rd edition</strong>‚Äîwhich addresses one of the most critical challenges in collaborative robotics: enabling safe, reliable transfer of objects from human hands to robotic grippers. Building on the success of previous editions at <a href="https://corsmal.github.io/rgm24icra/index.html" target="_blank">ICRA 2024</a> and <a href="https://corsmal.github.io/rgmc2025-handover-track/" target="_blank">ICRA 2025</a>, this track continues to push the boundaries of real-world human-robot collaboration.</p>

                <div class="track-card">
                    <h3>ü´±ü•§ü§ñ Real-Time Physical Property Estimation</h3>
                    <p>The core challenge: <strong>Can your robot estimate what it's receiving‚Äîin real-time‚Äîand respond safely?</strong></p>
                    <p>Teams must design solutions that enable robots to infer the physical properties (mass, stiffness, fill level) of objects during dynamic handovers, using only affordable vision-based perception. This is harder than it sounds. Consider the real-world complexities:</p>
                    <ul>
                        <li><strong>Unknown objects:</strong> Food containers and drinking glasses of varying shapes and sizes</li>
                        <li><strong>Unknown content:</strong> Containers may be empty or filled with unknown substances at unknown levels</li>
                        <li><strong>Unknown physics:</strong> The robot must estimate mass and stiffness on-the-fly, with no prior knowledge</li>
                        <li><strong>Perceptual challenges:</strong> Illumination variations, reflections, transparencies, and occlusions from both the human and robot</li>
                        <li><strong>Hardware constraints:</strong> No motion capture systems, markers, or specialized sensors‚Äîonly affordable cameras</li>
                    </ul>
                </div>

                <h3>Why This Matters</h3>
                <p>Human-robot handover is fundamental to collaborative robotics. From manufacturing to assistive robotics to household automation, robots that can safely receive objects from humans open entirely new possibilities. However, the task demands simultaneous excellence in perception, control, safety, and generalization. By solving handover, we're pushing robotics closer to real-world deployment in diverse environments.</p>

                <!-- What Participants Get -->
                <h2>What Participants Gain</h2>
                <p>RGMC offers far more than competition glory. Here's what participating teams receive:</p>

                <div class="opportunities">
                    <div class="opportunity-item">
                        <strong>ü§ñ Real Hardware Access</strong>
                        <p>Test your algorithms on UR5 and Franka Emika Panda robots at the competition site (based on availability)</p>
                    </div>
                    <div class="opportunity-item">
                        <strong>üìä Benchmark & Research</strong>
                        <p>Benchmark against state-of-the-art solutions and contribute to advancing the field in real conditions</p>
                    </div>
                    <div class="opportunity-item">
                        <strong>üìù Publication Opportunity</strong>
                        <p>Contribute peer-reviewed research articles to the Topical Collection in <em>Autonomous Robots</em></p>
                    </div>
                    <div class="opportunity-item">
                        <strong>üì∫ Global Visibility</strong>
                        <p>Showcase your demo video on the RGMC YouTube channel, reaching the research community worldwide</p>
                    </div>
                    <div class="opportunity-item">
                        <strong>üíª Free Tools</strong>
                        <p>Secure a free MATLAB license to support your solution development</p>
                    </div>
                    <div class="opportunity-item">
                        <strong>üèÜ Recognition & Prizes</strong>
                        <p>Win cash rewards for top-performing teams and earn recognition at ICRA 2026</p>
                    </div>
                </div>

                <!-- Important Dates -->
                <h2>Key Dates & Application Process</h2>

                <div class="deadline-box">
                    <div class="deadline-label">‚è∞ Extended Application Deadline</div>
                    <div class="deadline-date">23 February 2026</div>
                    <div class="deadline-note">Maximum of 6 teams will qualify for on-site participation</div>
                </div>

                <p><strong>How to Apply:</strong> Fill out the registration form at: <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0ZXvTqP-bP9he-R2aoC4QZjUnlG_qPDJcfQWrcxvJGZ-sSw/viewform?usp=header" target="_blank">RGMC Registration Form</a></p>

                <p><strong>Note:</strong> Applications after the deadline may be considered based on available spots and solution readiness. With 33+ teams already applied across all four tracks, early submission is recommended.</p>

                <!-- Learn More -->
                <h2>Get Started</h2>
                <p>Ready to join? Here are your next steps:</p>

                <ol>
                    <li><strong>Visit the official RGMC website:</strong> <a href="https://sites.google.com/view/rgmcomp" target="_blank">https://sites.google.com/view/rgmcomp</a></li>
                    <li><strong>Explore detailed track information:</strong> <a href="https://corsmal.github.io/events/rgmc/icra2026/" target="_blank">https://corsmal.github.io/events/rgmc/icra2026/</a></li>
                    <li><strong>Submit your application</strong> by 23 February 2026</li>
                    <li><strong>Prepare your solution</strong> and test it on the competition hardware</li>
                    <li><strong>Showcase your work</strong> at ICRA 2026 in Vienna</li>
                </ol>

                <!-- Call to Action -->
                <div class="cta-section">
                    <h3>Ready to Advance Robotic Manipulation?</h3>
                    <p>Join 33+ teams competing at the cutting edge of real-world robotics. The Human-to-Robot Handover track awaits your innovation.</p>
                    <div class="cta-buttons">
                        <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0ZXvTqP-bP9he-R2aoC4QZjUnlG_qPDJcfQWrcxvJGZ-sSw/viewform?usp=header" class="btn btn-primary" target="_blank">Apply Now</a>
                        <a href="https://corsmal.github.io/events/rgmc/icra2026/" class="btn btn-secondary" target="_blank">Learn More</a>
                    </div>
                </div>

                <!-- Community & Impact -->
                <h2>The RGMC Community & Impact</h2>
                <p>Since its inception in 2016, RGMC has grown into a thriving community of researchers and practitioners advancing the state of robotic grasping and manipulation. The competition has published findings in <em>IEEE Robotics & Automation Magazine</em> and maintains an active <a href="https://www.youtube.com/channel/UC8F4S4EjTAo2JbwdzbyKnCA" target="_blank">YouTube channel</a> featuring 23+ demo videos from competing teams across multiple editions.</p>

                <p>Beyond the competition itself, RGMC organizes annual workshops to discuss trends, challenges, and future directions in benchmarking robotic manipulation. These community efforts have established RGMC as a key venue for validating robotic solutions in practical, reproducible settings.</p>

                <!-- About RGMC -->
                <h2>About RGMC</h2>
                <p>The Robotic Grasping and Manipulation Competition has been advancing the field since 2016, with ten completed editions and the 11th now underway. RGMC is organized by leading researchers in robotics and supported by industry partners committed to advancing autonomous manipulation. The competition takes place annually at top-tier robotics conferences (ICRA or IROS), creating a global forum for collaborative research and benchmarking.</p>

                <p>To date, RGMC has published competition results and analysis in <em>IEEE Robotics & Automation Magazine</em>, produced three dedicated workshops at IROS, and maintains a growing archive of 23+ demo videos on the RGMC YouTube channel showcasing team innovations.</p>

                <p><strong>Questions?</strong> Visit the official websites or contact the organizers directly through the competition platform.</p>
            </div>

            <div class="article-footer">
                <div class="author-info">
                    <p><strong>About This Post</strong></p>
                    <p>This article provides an overview of the 11th Robotic Grasping and Manipulation Competition, with special focus on the Human-to-Robot Handover track. For detailed technical information, please visit the official competition website and track documentation.</p>
                </div>

                <div class="nav-links">
                    <a href="#" class="nav-link">
                        <div class="nav-link-label">‚Üê Back</div>
                        <div class="nav-link-title">All Blog Posts</div>
                    </a>
                    <a href="#" class="nav-link">
                        <div class="nav-link-label">Next ‚Üí</div>
                        <div class="nav-link-title">Coming Soon</div>
                    </a>
                </div>
            </div>
        </article>
    </main>
    
	<!--  -->
	<br><br><br>
	<footer class="site-footer">
	<div class="footer-col social-col" aria-label="Social media" style="text-align:center;">  
		<a href="https://orcid.org/0000-0002-8227-8529" aria-label="ORCID" rel="noopener noreferrer" target="_blank"><i class="ai ai-orcid ai-fw" aria-hidden="true"></i></a>
		<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao" aria-label="Google Scholar" rel="noopener noreferrer" target="_blank"><i class="ai ai-fw ai-google-scholar" aria-hidden="true"></i></a>
		<a href="https://github.com/kerolex/" aria-label="GitHub" rel="noopener noreferrer" target="_blank" ><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>				
		<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US" aria-label="LinkedIn" rel="noopener noreferrer" target="_blank"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i></a>
		<a href="https://bsky.app/profile/axompi.bsky.social" target="_blank" aria-label="Bluesky" rel="noopener noreferrer"><i class="fa-brands fa-bluesky" aria-hidden="true"></i></a>
	</div>
	<p>
		Copyright &copy; 2015-<span id="currentYear"></span> - Alessio Xompero
	</p>
	</footer>

    <script>
        // Smooth scroll for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                const href = this.getAttribute('href');
                if (href !== '#') {
                    e.preventDefault();
                    const target = document.querySelector(href);
                    if (target) {
                        target.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                }
            });
        });

        // Add reading time indicator
        const content = document.querySelector('.article-content');
        const words = content.innerText.split(/\s+/).length;
        const readingTime = Math.ceil(words / 200);
        console.log(`Estimated reading time: ${readingTime} minutes`);
    </script>
</body>
</html>

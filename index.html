<!DOCTYPE html>
<html lang = "en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139569814-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139569814-1');
	</script>


	<title>Alessio Xompero</title>
	<meta name="image" property="og:image" content="images/AlessioXompero.JPG">
	<link rel="shortcut icon" href="images/AlessioXompero.JPG" />
	<link href = "css/bootstrap.min.css" rel = "stylesheet">
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="css/mystyle.css">
	<link rel="stylesheet" href="css/all.css">
	<link rel="stylesheet" href="css/academicons.css">  
</head>

<body>     

	<div id="menu">
		<!-- <p style="float:left; font-size: 14.0pt;"><b style="font-weight: bold;">Alessio Xompero, Ph.D.</b></p> -->
		<nav style="text-align:left">
			<ul>
				<li><a href="index.html" class="active"><b style="font-weight: bold;font-size: 13.0pt;padding-right:20px">Alessio Xompero, Ph.D.</b></a></li>
				<!-- <li class="subnav">
			    <button class="subnavbtn">Research <i class="fa fa-caret-down"></i></button>
			    <div class="subnav-content">
			      <a href="publications.html">Publications</a>
			      <a href="#team">Projects</a>
			    </div>
			  </li>  -->
				<li><a href="publications.html">Publications</a></li>
				<li><a href="talks.html">Talks</a></li>
				<li><a href="data.html">Data & Code</a></li>
				<li><a href="services.html">Services</a></li>
				<li><a href="projects.html">Projects</a></li>
				<li><a href="blog.html">Blog</a></li>
				<li><a href="bio.html">Biography</a></li>
			</ul>
		</nav>
	</div>
	<div id="about">
		<div class="fixed-content">
			<div>
			<!-- <b style="font-weight: bold;font-size: 13.0pt;padding-right:20px">Alessio Xompero, Ph.D.</b><br> -->
			<img src="images/AlessioXompero.JPG" style="border-radius:0%;width:100%;text-align:center" alt="avatar"/>
			<br>
<!-- 			<p style="text-align:left;padding-left:20px;">
				<a style="color:#6699ff" href="resources/AlessioX_CV_2020.pdf">CV (2020)</a><br> 
				<a style="color:#6699ff" href="https://scholar.google.it/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao">GoogleScholar</a><br>
				<a style="color:#6699ff" href="https://www.linkedin.com/in/alessioxompero/?locale=en_US">LinkedIn</a><br>
				<a style="color:#6699ff" href="https://orcid.org/0000-0002-8227-8529">ORC-ID</a>
			</p> -->
			<br>
			<!-- <div class="author__urls-wrapper"> 
				<ul class="author__urls social-icons" style="text-align:left;"> -->
					<!-- <li>
						<a href="mailto:a.xompero@qmul.ac.uk"><i class="fa fa-fw fa-envelope" aria-hidden="true" style="padding-right: 1.5em;"></i>Email</a>
					</li> -->
					<!-- <li>
						<a href="https://twitter.com/aXompi"><i class="fab fa-fw fa-twitter" aria-hidden="true" style="padding-right: 1.5em;"></i>Twitter</a>
					</li>	
					<li>
						<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US"><i class="fab fa-fw fa-linkedin" aria-hidden="true" style="padding-right: 1.5em;"></i>LinkedIn</a>
					</li>
					<li>
						<a href="https://github.com/kerolex/"><i class="fab fa-fw fa-github" aria-hidden="true" style="padding-right: 1.5em;"></i>GitHub</a>
					</li>	
					<li>
						<a href="https://orcid.org/0000-0002-8227-8529"><i class="ai ai-orcid ai-fw" aria-hidden="true" style="padding-right: 1.5em;"></i>ORC-ID</a>
					</li>	
					<li>
						<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao"><i class="ai ai-fw ai-google-scholar" aria-hidden="true" style="padding-right: 1.5em;"></i>Google Scholar</a>
					</li>	
				</ul>
			</div> -->
			<div class="author__urls-wrapper">  
				<ul class="author__urls social-icons" style="text-align:center;">
					<li>
						<a href="https://twitter.com/aXompi"><i class="fab fa-fw fa-twitter" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
					</li>	
					<li>
						<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US"><i class="fab fa-fw fa-linkedin" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
					</li>
					<li>
						<a href="https://github.com/kerolex/"><i class="fab fa-fw fa-github" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
					</li>	
					<li>
						<a href="https://orcid.org/0000-0002-8227-8529"><i class="ai ai-orcid ai-fw" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
					</li>	
					<li>
						<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao"><i class="ai ai-fw ai-google-scholar" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
					</li>	
				</ul>
			</div>
			<br><br>
			<a class="twitter-timeline" data-lang="en" data-height="300" data-theme="light" href="https://twitter.com/aXompi?ref_src=twsrc%5Etfw">Tweets by aXompi</a>
			<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
		</div>
	</div>
		<div class="scrolling-content">
			<p style="padding-top:30px; text-align:justify">
				Alessio is a Postdoctoral Research Assistant with the Centre for Intelligent Sensing and the School of Electronic Engineerging and Computer Science at Queen Mary University of London (QMUL), UK. In  collaboration with and under the supervision of <a href="http://www.eecs.qmul.ac.uk/~andrea/">Prof. Andrea Cavallaro</a>, Alessio currently investigates novel, robust, deployable  multi-modal (audio-visual) models for human-to-robot handovers under the project "Collaborative Object Recognition, Shared Manipulation and Learning (<a href="http://corsmal.eecs.qmul.ac.uk">CORSMAL</a>)".<br><br>

				Alessio obtained his Ph.D. in Electronic Engineering, with the thesis titled "Local features for view matching across independently moving cameras", from Queen Mary University of London, UK, in September 2020.<br><br>

				Alessio is an IEEE Member and IEEE Signal Processing Society member, and a reviewer for international conferences and journals, including IEEE International Conference on Image Processing (ICIP), IEEE International Conference on Acoustic, Speech, and Signal Processing (ICASSP), IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE International Conference on Pattern Recognition (ICPR), IEEE Transactions on Multimedia, IEEE Robotics and Automation Letters, IEEE Sensors Journal. 
			</p>
			<h2>Research interests</h2>
			<p style="text-align:left">
				Computer Vision | Machine and deep learning | Multi-modal fusion | Image and video processing | Perception for robotics
			</p>
			<br>
			<h2>Most recent talk</h2>
			<div class="video-container" style="text-align:center">
				<iframe width="560" height="315" src="https:///www.youtube.com/embed/MoFhI40Wd0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			</div>
			<p style="text-align:center">
				<a style="font-weight: bold;">Cross-Camera View-Overlap Recognition</a><br>
				<i>International Workshop on Distributed Smart Cameras</i> (24 October 2022)<br> 
					at European Conference on Computer Vision (ECCV)
			</p>
			<br>
			<h2>News</h2>
			<table class="tg" width="100%">
				<tr>
					<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2023/01/01</td>
					<td class="tg-zv4m" style="text-align:left;">Joining and contributing for the next year into the project <a href="https://graphnex.eecs.qmul.ac.uk"><u>GraphNEx</u></a></td>
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/12/07</td>
				<td class="tg-zv4m" style="text-align: left;">Lecture on interest points (from SIFT, binary descriptor to recent deep learning based methods) at the ECS709 Module: Introduction to Computer Vision (QMUL)</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/12/06</td>
				<td class="tg-zv4m" style="text-align: left;">Presenting the project CORSMAL and its achievements at the <a href="https://www.robotics.qmul.ac.uk/events/4645/arq-robotics-centre-research-day-2022"><u>ARQ-Robotics Centre Research Day 2022</u></a></td>
				</tr>				
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/10/21</td>
				<td class="tg-zv4m" style="text-align: left;">Released the <a href="https://doi.org/10.5281/zenodo.7235890"><u>data</u></a> and <a href="https://github.com/kerolex/CrossCameraViewOverlapRecognition"><u>code</u></a> associated to the work on <i>Cross-Camera View-Overlap Recognition</i></td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/12/07</td>
				<td class="tg-zv4m" style="text-align: left;">Lecture on Deep Learning Models for Computer Vision at the ECS709 Module: Introduction to Computer Vision (QMUL)</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/09/14</td>
				<td class="tg-zv4m" style="text-align: left;">Presented a video demo of the project CORSMAL at <a href="https://icdl2022.qmul.ac.uk"><u>IEEE International Conference on Development and Learning (ICDL 2022)</u></a></td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/05/27</td>
				<td class="tg-zv4m" style="text-align: left;">Our paper "Audio-Visual Object Classification for Human-Robot Collaboration" has been ranked 4th for <a href="https://2022.ieeeicassp.org/stats/TopPosters.php"><u>the most viewed posters</u></a> and 22nd for <a href="https://2022.ieeeicassp.org/stats/TopPapers.php"><u>the most downloaded papers</u></a> at IEEE ICASSP 2022</td>	
				</tr>
				<tr>
					<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/05/27</td>
					<td class="tg-zv4m" style="text-align: left;">Outstanding Reviewer Recognition at IEEE ICASSP 2022 (31 reviewers selected)</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/04/21</td>
				<td class="tg-zv4m" style="text-align: left;"><a href="http://cis.eecs.qmul.ac.uk/visualadversarial.html"><u>Webpage</u></a> of the chapter on Visual Adversarial Attacks and Defenses is now online!</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:5%;font-weight: normal;text-align: center;">2022/03/28</td>
				<td class="tg-zv4m" style="text-align: left;">CORSMAL features as <a href="https://youtu.be/WeTaFZkoyuc?t=7333">CHIST-ERA Open Science Success Story</a> at the CHIST-ERA Projects Seminar 2022</td>	
				</tr>
			</table>
			<br>
			<h2>Selected publications</h2>
			<ul>
				<li><a href="https://doi.org/10.48550/arXiv.2107.12719" TARGET = "_blank"><u>The CORSMAL benchmark for the prediction of the properties of containers</u></a>, IEEE Access, vol. 10, 2022</li>
				<li><a href="https://doi.org/10.1109/ICASSP43922.2022.9746336" TARGET = "_blank"><u>Audio-Visual Object Classification for Human-Robot Collaboration</u></a>, IEEE ICASSP 2022</li>
				<li><a href="https://ieeexplore.ieee.org/document/8960644" TARGET = "_blank"><u>A spatio-temporal multi-scale binary descriptor</u></a>, IEEE Transactions on Image Processing 2020.</li>
				<li><a href="https://doi.org/10.1109/ICASSP40776.2020.9054112" TARGET = "_blank"><u>Multi-view shape estimation of transparent containers</u></a>, IEEE ICASSP 2020</li>
				<li><a href="https://doi.org/10.1109/ICIP.2018.8451024" TARGET = "_blank"><u>MORB: a multi-scale binary descriptor</u></a>, IEEE ICIP 2018</li>
			</ul>
		</div>
		<div style="clear:both"></div>
	</div>
	<br><br><br>
	<footer class="site-footer">
		<div class="footer-col social-col" style="text-align:center;">  
				<a href="https://twitter.com/aXompi"><i class="fab fa-fw fa-twitter" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US"><i class="fab fa-fw fa-linkedin" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://github.com/kerolex/"><i class="fab fa-fw fa-github" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://orcid.org/0000-0002-8227-8529"><i class="ai ai-orcid ai-fw" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao"><i class="ai ai-fw ai-google-scholar" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
			</div>
		<p>
			Copyright Â© 2015-2023 - Alessio Xompero
		</p>
	</footer>
</body>

<script>
	function w3_open() {
		document.getElementById("mySidebar").style.display = "block";
	}

	function w3_close() {
		document.getElementById("mySidebar").style.display = "none";
	}
</script>
</html>



<!-- <h2>News</h2>
			<p>
				- 2023/01/01: Joining and contributing for the next year into the project <a href="https://graphnex.eecs.qmul.ac.uk"><u>GraphNEx</u></a><br>
				- 2022/12/07: Lecture on interest points (from SIFT, binary descriptor to recent deep learning based methods) at the ECS709 Module: Introduction to Computer Vision (QMUL)<br>
				- 2022/12/06: Presenting the project CORSMAL and its achievements at the <a href="https://www.robotics.qmul.ac.uk/events/4645/arq-robotics-centre-research-day-2022"><u>ARQ-Robotics Centre Research Day 2022</u></a><br>
				- 2022/10/24: Presenting virtually <i>Cross-Camera View-Overlap Recognition</i> at the <a href="https://iwdsc.github.io"><u>International Workshop on Distributed Smart Cameras</u></a> (IWDSC) at the 2022 European Conference on Computer Vision (ECCV)<br>
				- 2022/10/21: Released the <a href="https://doi.org/10.5281/zenodo.7235890"><u>data</u></a> and <a href="https://github.com/kerolex/CrossCameraViewOverlapRecognition"><u>code</u></a> associated to the work on <i>Cross-Camera View-Overlap Recognition</i><br>
				- 2022/12/07: Lecture on Deep Learning Models for Computer Vision at the ECS709 Module: Introduction to Computer Vision (QMUL)<br>
				- 2022/09/14: Presented a video demo of the project CORSMAL at <a href="https://icdl2022.qmul.ac.uk"><u>IEEE International Conference on Development and Learning (ICDL 2022)</u></a><br>
				- 2022/08/26: Our paper "<a href="https://doi.org/10.48550/arXiv.2208.11661"><u>Cross-Camera View-Overlap Recognition</u></a>" has been accepted to the <a href="https://iwdsc.github.io"><u>International Workshop on Distributed Smart Cameras</u></a> (IWDSC) at the 2022 European Conference on Computer Vision (ECCV)<br>
				- 2022/05/27: Our paper "Audio-Visual Object Classification for Human-Robot Collaboration" has been ranked 4th for <a href="https://2022.ieeeicassp.org/stats/TopPosters.php"><u>the most viewed posters</u></a> and 22nd for <a href="https://2022.ieeeicassp.org/stats/TopPapers.php"><u>the most downloaded papers</u></a> at IEEE ICASSP 2022<br>
				- 2022/05/27: Outstanding Reviewer Recognition at IEEE ICASSP 2022 (31 reviewers selected)<br>
				- 2022/04/21: Presentations of the CORSMAL Challenge will be hosted virtually on <a href="https://2022.ieeeicassp.org/technical_program.php?T=V"><u>Gather.Town</u></a> at IEEE ICASSP 2022 on Saturday 7 May, 1pm UTC<br>
				- 2022/04/21: <a href="http://cis.eecs.qmul.ac.uk/visualadversarial.html"><u>Webpage</u></a> of the chapter on Visual Adversarial Attacks and Defenses is now online!<br>
				- 2022/03/28: CORSMAL features as <a href="https://youtu.be/WeTaFZkoyuc?t=7333">CHIST-ERA Open Science Success Story</a> at the CHIST-ERA Projects Seminar 2022<br>
				- 2022/03/26: <a href="https://doi.org/10.1109/ACCESS.2022.3166906">Paper</a> on the CORSMAL Benchmark framework accepted at IEEE Access<br>
				- 2022/02/15: <a href="https://arxiv.org/abs/2203.01977">Paper</a> on the overview of the CORSMAL Challenge accepted at IEEE ICASSP<br>
				- 2021/12/07: Co-organising the <a href="http://cis.eecs.qmul.ac.uk/school2021.html">CORSMAL Challenge</a> at the 2021 Intelligent Sensing Winter School<br>
			</p> -->
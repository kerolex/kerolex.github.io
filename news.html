<!DOCTYPE html>
<html lang = "en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139569814-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-139569814-1');
	</script>

	<title>Alessio Xompero, PhD</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="image" property="og:image" content="images/AlessioXompero.JPG">

	<link rel="shortcut icon" href="images/profile_icon_ax.JPG" />
	<link rel="stylesheet" href="../css/bootstrap.min.css" >
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="css/mystyle.css">
	<link rel="stylesheet" href="css/all.css">
	<link rel="stylesheet" href="css/academicons.css"> 

	<script src="js/menu.js" defer></script>
</head>

<body>     
	<div id="menu">
		<div class="logo">
			<a href="index.html" class="active"><b>Alessio Xompero, Ph.D.</b></a>			
		</div>

		<!-- From https://www.menucool.com/ddmenu/one-menu-for-all-pages -->
		<nav>
			<div class="menu-toggle"><span></span></div>
			<ul>			
				<li class="subnav">
					<a>Research</a>
					<div class="subnav-content">
						<a href="research/publications.html">Publications</a>
						<!-- <br> -->
						<a href="research/data.html">Data</a>
						<!-- <br> -->
						<a href="research/software.html">Software</a>
						<!-- <br> -->
						<a href="research/projects.html">Projects</a>
						<!-- <br> -->
						<a href="research/talks.html">Talks</a>
					</div>
				</li>
				<li class="subnav">
					<a>Services</a>
					<div class="subnav-content">
						<!-- <a href="services/teaching.html">Teaching</a><br> -->
						<a href="services/reviewing.html">Reviewing</a>
						<!-- <br> -->
						<a href="services/openscience.html">Community</a>
					</div>
				</li>
				<li class="subnav">
					<a>Teaching</a>
					<div class="subnav-content">
						<a href="teaching/teaching.html">Teaching</a>
					</div>
				</li>
				<li class="subnav">
					<a>News</a>
					<div class="subnav-content">
						<a href="news.html">All news</a>
						<!-- <br> -->
						<a href="blog.html">Blog</a>
					</div>
				</li>
				<li class="subnav">
					<a>About</a>
					<div class="subnav-content">
						<a href="bio.html">Biography</a>
						<!-- <br> -->
						<a href="gallery.html">Gallery</a>
					</div>
				</li>
			</ul>
		</nav>
	</div>

	<div id="section">
		<div class="scrolling-content">
			<h2>News</h2>
			<table class="tg" width="100%">
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2025/05/09</td>
					<td class="tg-zv4m" style="text-align:left;">Pre-print of our article "Visual Affordances: Enabling robots to understand object functionality", currently under review, available on <a href="https://doi.org/10.48550/arXiv.2505.05074"><u>ArXiv</u></a></td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2025/05/09</td>
					<td class="tg-zv4m" style="text-align:left;">Workshop "Benchmarking via Competitions in Robotic Grasping and Manipulation (2nd Edition)" accepted at IROS 2025 (see <a href="https://sites.google.com/view/iros2025-bench-competitions/"><u>webpage</u></a>)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2025/03/31</td>
					<td class="tg-zv4m" style="text-align:left;">Article, titled "Stereo Hand-Object Reconstruction for Human-to-Robot Handover", accepted at IEEE Robotics and Automation Letters (RA-L) [<a href="https://doi.org/10.48550/arXiv.2412.07487"><u>arxiv</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2025/03/01</td>
					<td class="tg-zv4m" style="text-align:left;">Paper accepted at Privacy Enhancing Technologies Symposium (PETS) 2025 and in the journal Proceedings on Privacy Enhancing Technologies (PoPETs), Volume 2025, Issue 3, 2025</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2025/01/15</td>
					<td class="tg-zv4m" style="text-align:left;">I am a guest editor for the IEEE RA-P Special Collection of "Autonomous Robotic Grasping and Manipulation in Real-World Applications" [<a href="blog.html#rap-special-collection"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/12/15</td>
					<td class="tg-zv4m" style="text-align:left;">The Robotic Grasping and Manipulation Competition at ICRA 2025 is now live and accepting applications. Join our handover track competition [<a href="https://sites.google.com/view/rgmc2025/home"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/12/11</td>
					<td class="tg-zv4m" style="text-align:left;">Pre-print and webpage of our recent work on Stereo Hand-Object Reconstruction for Human-to-Robot Handover now online [<a href="https://qm-ipalab.github.io/StereoHO/"><u>link</u></a>]</td>
				</tr>				
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/12/11</td>
					<td class="tg-zv4m" style="text-align:left;">Competition column about the Robotic Grasping and Manipulation Competition at ICRA 2024 is online in the IEEE Robotics & Automation Magazine (Issue 4: December 2024) [<a href="https://doi.org/10.1109/MRA.2024.3481609"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/11/20</td>
					<td class="tg-zv4m" style="text-align:left;">Competition column about the Robotic Grasping and Manipulation Competition at ICRA 2024 to appear in IEEE Robotics & Automation Magazine (December 2024) [<a href="https://doi.org/10.1109/MRA.2024.3481609"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/11/20</td>
					<td class="tg-zv4m" style="text-align:left;">The 10th Robotic Grasping and Manipulation Competition has been accepted at ICRA 2025 [<a href="https://sites.google.com/view/rgmc2025"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/11/17</td>
					<td class="tg-zv4m" style="text-align:left;">I will serve as a reviewer for the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR)  [<a href="https://cvpr.thecvf.com/"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/09/23</td>
					<td class="tg-zv4m" style="text-align:left;">Recognised as an outstanding reviewer for ECCV 2024 [<a href="https://eccv.ecva.net/Conferences/2024/Reviewers"><u>link</u></a>]</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/08/14</td>
					<td class="tg-zv4m" style="text-align:left;">Accepted paper at the 12th International Workshop on Assistive Computer Vision and Robotics (ACVR) at ECCV 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/06/26</td>
					<td class="tg-zv4m" style="text-align:left;">Accepted proposal for the 2024 Idiap Create Challenge</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/06/17</td>
					<td class="tg-zv4m" style="text-align:left;">Attending the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024) in Seattle, USA, and presenting "Explaining models relating objects and privacy" as poster at the XAI4CV workshop</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/05/23</td>
					<td class="tg-zv4m" style="text-align:left;">Recognised as outstanding reviewer for CVPR 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/01/20</td>
					<td class="tg-zv4m" style="text-align:left;">Attending the 2024 International Conference on Robotics and Automation (ICRA) in Yokohama, Japan, and co-organising the Human-to-Robot Handovers Sub-track within the Robotic Grasping and Manipulation Competition</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/04/16</td>
					<td class="tg-zv4m" style="text-align:left;">Presenting the project GraphNEx at the annual CHIST-ERA Projects Seminar 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/04/07</td>
					<td class="tg-zv4m" style="text-align:left;">Paper accepted as poster at XAI4CV Workshop at CVPR 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/02/07</td>
					<td class="tg-zv4m" style="text-align:left;">Reviewer for the European Conference on Computer Vision (ECCV) 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/01/30</td>
					<td class="tg-zv4m" style="text-align:left;">Reviewer for the IEEE International Conference on Image Processing (ICIP) 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2024/01/20</td>
					<td class="tg-zv4m" style="text-align:left;">Co-organiser of the Human-to-Robot Handovers Sub-track within the Robotic Grasping and Manipulation Competition at the 2024 International Conference on Robotics and Automation (ICRA)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/11/20</td>
					<td class="tg-zv4m" style="text-align:left;">Attending the 3rd GraphNEx workshop in Lyon</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/11/19</td>
					<td class="tg-zv4m" style="text-align:left;">Reviewer for the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/10/17</td>
					<td class="tg-zv4m" style="text-align:left;">Reviewer for the 2024 IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/10/04</td>
					<td class="tg-zv4m" style="text-align:left;">Reviewer for the 2024 IEEE International Conference on Robotics and Automation (ICRA)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/10/02</td>
					<td class="tg-zv4m" style="text-align:left;">Attending the International Conference on Computer Vision (ICCV) in Paris</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/08/05</td>
					<td class="tg-zv4m" style="text-align:left;">Paper (that I co-authored) accepted at the 11th Int. Workshop on Assistive Computer Vision and Robotics (ACVR) at ICCV 2023</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/06/11</td>
					<td class="tg-zv4m" style="text-align:left;">Awarded outstanding reviewer recognition at IEEE ICASSP 2023</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/04/28</td>
					<td class="tg-zv4m" style="text-align:left;">Visiting at Idiap Research Institute, in Martigny, Switzerland (29 April - 25 May)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/05/03</td>
					<td class="tg-zv4m" style="text-align:left;">Attending GraphNEx workshop (3-5 May) at Idiap Research Institute, in Martigny, Switzerland</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/04/26</td>
					<td class="tg-zv4m" style="text-align:left;">Internal tutorial (day 2): "The reviewer doesn't understand & is wrong! Transitioning into the reviewer's shoes" (online & in-person)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/04/01</td>
					<td class="tg-zv4m" style="text-align:left;">Attending and presenting the project GraphNEx at the <a href="https://www.chistera.eu/news/join-chist-era-projects-seminar-2023-april-4"><u>CHIST-ERA Projects Seminar 2023</u></a> (poster, presentation)</td>
				</tr>
				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/03/22</td>
					<td class="tg-zv4m" style="text-align:left;">Internal tutorial: "The reviewer doesn't understand & is wrong! Transitioning into the reviewer's shoes" (online & in-person)</td>
				</tr>

				<tr>
					<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2023/01/01</td>
					<td class="tg-zv4m" style="text-align:left;">Joining and contributing for the next year into the project <a href="https://graphnex.eecs.qmul.ac.uk"><u>GraphNEx</u></a></td>
				</tr>
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/12/07</td>
				<td class="tg-zv4m" style="text-align: left;">Lecture on interest points (from SIFT, binary descriptor to recent deep learning based methods) at the ECS709 Module: Introduction to Computer Vision (QMUL)</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/12/06</td>
				<td class="tg-zv4m" style="text-align: left;">Presenting the project CORSMAL and its achievements at the <a href="https://www.robotics.qmul.ac.uk/events/4645/arq-robotics-centre-research-day-2022"><u>ARQ-Robotics Centre Research Day 2022</u></a></td>
				</tr>				
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/10/21</td>
				<td class="tg-zv4m" style="text-align: left;">Released the <a href="https://doi.org/10.5281/zenodo.7235890"><u>data</u></a> and <a href="https://github.com/kerolex/CrossCameraViewOverlapRecognition"><u>code</u></a> associated to the work on <i>Cross-Camera View-Overlap Recognition</i></td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/10/07</td>
				<td class="tg-zv4m" style="text-align: left;">Lecture on Deep Learning Models for Computer Vision at the ECS709 Module: Introduction to Computer Vision (QMUL)</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/09/14</td>
				<td class="tg-zv4m" style="text-align: left;">Presented a video demo of the project CORSMAL at <a href="https://icdl2022.qmul.ac.uk"><u>IEEE International Conference on Development and Learning (ICDL 2022)</u></a></td>	
				</tr>
				<!-- <tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/05/27</td>
				<td class="tg-zv4m" style="text-align: left;">Our paper "Audio-Visual Object Classification for Human-Robot Collaboration" has been ranked 4th for <a href="https://2022.ieeeicassp.org/stats/TopPosters.php"><u>the most viewed posters</u></a> and 22nd for <a href="https://2022.ieeeicassp.org/stats/TopPapers.php"><u>the most downloaded papers</u></a> at IEEE ICASSP 2022</td>	
				</tr> -->
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/04/21</td>
				<td class="tg-zv4m" style="text-align: left;"><a href="http://cis.eecs.qmul.ac.uk/visualadversarial.html"><u>Webpage</u></a> of the chapter on Visual Adversarial Attacks and Defenses is now online!</td>	
				</tr>
				<tr>
				<td class="tg-km2t" style="width:10%;font-weight: normal;text-align: center;">2022/03/28</td>
				<td class="tg-zv4m" style="text-align: left;">CORSMAL features as <a href="https://youtu.be/WeTaFZkoyuc?t=7333">CHIST-ERA Open Science Success Story</a> at the CHIST-ERA Projects Seminar 2022</td>	
				</tr>
			</table>
			<!--
			<p>
				- 2023/01/01: Joining and contributing for the next year into the project <a href="https://graphnex.eecs.qmul.ac.uk"><u>GraphNEx</u></a><br>
				- 2022/12/07: Lecture on interest points (from SIFT, binary descriptor to recent deep learning based methods) at the ECS709 Module: Introduction to Computer Vision (QMUL)<br>
				- 2022/12/06: Presenting the project CORSMAL and its achievements at the <a href="https://www.robotics.qmul.ac.uk/events/4645/arq-robotics-centre-research-day-2022"><u>ARQ-Robotics Centre Research Day 2022</u></a><br>
				- 2022/10/24: Presenting virtually <i>Cross-Camera View-Overlap Recognition</i> at the <a href="https://iwdsc.github.io"><u>International Workshop on Distributed Smart Cameras</u></a> (IWDSC) at the 2022 European Conference on Computer Vision (ECCV)<br>
				- 2022/10/21: Released the <a href="https://doi.org/10.5281/zenodo.7235890"><u>data</u></a> and <a href="https://github.com/kerolex/CrossCameraViewOverlapRecognition"><u>code</u></a> associated to the work on <i>Cross-Camera View-Overlap Recognition</i><br>
				- 2022/12/07: Lecture on Deep Learning Models for Computer Vision at the ECS709 Module: Introduction to Computer Vision (QMUL)<br>
				- 2022/09/14: Presented a video demo of the project CORSMAL at <a href="https://icdl2022.qmul.ac.uk"><u>IEEE International Conference on Development and Learning (ICDL 2022)</u></a><br>
				- 2022/08/26: Our paper "<a href="https://doi.org/10.48550/arXiv.2208.11661"><u>Cross-Camera View-Overlap Recognition</u></a>" has been accepted to the <a href="https://iwdsc.github.io"><u>International Workshop on Distributed Smart Cameras</u></a> (IWDSC) at the 2022 European Conference on Computer Vision (ECCV)<br>
				- 2022/05/27: Our paper "Audio-Visual Object Classification for Human-Robot Collaboration" has been ranked 4th for <a href="https://2022.ieeeicassp.org/stats/TopPosters.php"><u>the most viewed posters</u></a> and 22nd for <a href="https://2022.ieeeicassp.org/stats/TopPapers.php"><u>the most downloaded papers</u></a> at IEEE ICASSP 2022<br>
				- 2022/05/27: Outstanding Reviewer Recognition at IEEE ICASSP 2022 (31 reviewers selected)<br>
				- 2022/04/21: Presentations of the CORSMAL Challenge will be hosted virtually on <a href="https://2022.ieeeicassp.org/technical_program.php?T=V"><u>Gather.Town</u></a> at IEEE ICASSP 2022 on Saturday 7 May, 1pm UTC<br>
				- 2022/04/21: <a href="http://cis.eecs.qmul.ac.uk/visualadversarial.html"><u>Webpage</u></a> of the chapter on Visual Adversarial Attacks and Defenses is now online!<br>
				- 2022/03/28: CORSMAL features as <a href="https://youtu.be/WeTaFZkoyuc?t=7333">CHIST-ERA Open Science Success Story</a> at the CHIST-ERA Projects Seminar 2022<br>
				- 2022/03/26: <a href="https://doi.org/10.1109/ACCESS.2022.3166906">Paper</a> on the CORSMAL Benchmark framework accepted at IEEE Access<br>
				- 2022/02/15: <a href="https://arxiv.org/abs/2203.01977">Paper</a> on the overview of the CORSMAL Challenge accepted at IEEE ICASSP<br>
				- 2021/12/07: Co-organising the <a href="http://cis.eecs.qmul.ac.uk/school2021.html">CORSMAL Challenge</a> at the 2021 Intelligent Sensing Winter School<br>
			</p> -->
		</div>
		<div style="clear:both"></div>
	</div>
	<br><br><br>
	<footer class="site-footer">
		<div class="footer-col social-col" style="text-align:center;">  
				<a href="https://twitter.com/aXompi"><i class="fab fa-fw fa-twitter" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://www.linkedin.com/in/alessioxompero/?locale=en_US"><i class="fab fa-fw fa-linkedin" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://github.com/kerolex/"><i class="fab fa-fw fa-github" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://orcid.org/0000-0002-8227-8529"><i class="ai ai-orcid ai-fw" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
				<a href="https://scholar.google.com/citations?user=r7jxqOAAAAAJ&hl=en&oi=ao"><i class="ai ai-fw ai-google-scholar" aria-hidden="true" style="padding-right: 1.5em;"></i></a>
			</div>
		<p>
			Copyright Â© 2015-2025 - Alessio Xompero
		</p>
	</footer>
</body>
</html>